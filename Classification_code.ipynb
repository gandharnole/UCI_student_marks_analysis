{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx796V5ZLpM7"
      },
      "source": [
        "## ðŸ§© Part 1: Merging Mathematics and Portuguese Student Datasets\n",
        "\n",
        "The dataset is split into two files â€” **student-math** and **student-por** â€” and there is **no unique student ID**.  \n",
        "To correctly merge students who appear in both subjects, we:\n",
        "\n",
        "âœ” Used all **non-grade and non-subject-specific columns** (e.g., age, school, parentsâ€™ education, address, etc.) as matching keys.  \n",
        "âœ” Excluded subject-specific columns like `G1_math`, `G2_math`, `G3_math`, `absences_math` and Portuguese equivalents.  \n",
        "âœ” Performed an **outer merge** so students appearing in only one dataset are still included.  \n",
        "âœ” Saved the merged dataset as `student_combined_data_final.csv` for further modeling.\n",
        "\n",
        "This will allow us to build **one classification model for Math** and **one for Portuguese**, using consistent student records.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEd_nagULNxs",
        "outputId": "0fe2e1cf-5d23-4bb5-f4fd-2929efc29f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matched students (identical on all non-subject columns): 162\n",
            "Math-only rows: 233\n",
            "Portuguese-only rows: 485\n",
            "Total rows in merged: 880\n",
            "âœ… Merged dataset saved as 'student_combined_data_final.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Load data ---\n",
        "math = pd.read_csv(\"student-mat.csv\")\n",
        "por  = pd.read_csv(\"student-por.csv\")\n",
        "\n",
        "# --- Grade & subject-specific columns ---\n",
        "math_subject_cols = ['G1_math', 'G2_math', 'G3_math', 'absences_math']\n",
        "por_subject_cols  = ['G1_por', 'G2_por', 'G3_por', 'absences_por']\n",
        "\n",
        "# --- Build strict match key: all shared non-subject, non-grade columns ---\n",
        "common_cols = sorted(list(set(math.columns).intersection(set(por.columns))))\n",
        "exclude_cols = set(math_subject_cols + por_subject_cols)\n",
        "key_cols = [c for c in common_cols if c not in exclude_cols]\n",
        "\n",
        "# --- Keep only key columns + Portuguese subject columns ---\n",
        "por_keep = por[key_cols + por_subject_cols].drop_duplicates(subset=key_cols, keep='first')\n",
        "\n",
        "# --- Merge: all columns from Math + Portuguese subject columns ---\n",
        "merged = pd.merge(\n",
        "    math, por_keep,\n",
        "    on=key_cols,\n",
        "    how='outer'\n",
        ")\n",
        "\n",
        "# --- Diagnostics ---\n",
        "has_math = merged[['G1_math', 'G2_math', 'G3_math']].notna().any(axis=1)\n",
        "has_por  = merged[['G1_por', 'G2_por', 'G3_por']].notna().any(axis=1)\n",
        "matched  = (has_math & has_por).sum()\n",
        "only_math = (has_math & ~has_por).sum()\n",
        "only_por  = (~has_math & has_por).sum()\n",
        "\n",
        "print(f\"Matched students (identical on all non-subject columns): {matched}\")\n",
        "print(f\"Math-only rows: {only_math}\")\n",
        "print(f\"Portuguese-only rows: {only_por}\")\n",
        "print(f\"Total rows in merged: {len(merged)}\")\n",
        "\n",
        "# --- Save final combined dataset ---\n",
        "merged.to_csv(\"student_combined_data_final.csv\", index=False)\n",
        "print(\"âœ… Merged dataset saved as 'student_combined_data_final.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK5HZ0M-Ow3i"
      },
      "source": [
        "## ðŸŽ¯ Part 2: Binary Classification â€” Predicting Pass/Fail in Mathematics (G3_math)\n",
        "\n",
        "### âœ… Objective:\n",
        "Convert the regression task into a **binary classification problem**:\n",
        "- **Pass = 1** if G3_math > 15  \n",
        "- **Fail = 0** if G3_math â‰¤ 15\n",
        "\n",
        "### âœ… Why Logistic Regression?\n",
        "- The professor specifically asked us to use **linear models only**.\n",
        "- Logistic Regression is a **linear classification model**.\n",
        "- It provides **interpretable coefficients and odds ratios**, useful for analysis.\n",
        "\n",
        "### âœ… Important Constraints Followed:\n",
        "- We are **not using G1 or G2**, because they strongly correlate with G3 and make the task trivial.\n",
        "- We only use demographic, behavioral, and academic support features.\n",
        "- Missing values in selected features are removed to avoid bias.\n",
        "\n",
        "### âœ… Pipeline Steps:\n",
        "1. Create binary target column (`G3_math_pass`).  \n",
        "2. Select meaningful predictors (studytime, failures, alcohol consumption, etc.).  \n",
        "3. Split into training/testing sets using **stratified sampling**.  \n",
        "4. Apply **StandardScaler + OneHotEncoder** using `ColumnTransformer`.  \n",
        "5. Train `LogisticRegression(class_weight='balanced')` to handle class imbalance.  \n",
        "6. Evaluate using **Accuracy**, **Precision**, **Recall**, **F1**, **ROC-AUC**, and **Cross-Validation**.\n",
        "\n",
        "This step helps us understand whether passing a Math exam can be predicted using socio-demographic and behavioral features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldWd_RhtOwR7",
        "outputId": "5bd7e198-785f-4cc7-ad6a-c0f60ad4e431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6835443037974683\n",
            "Precision: 0.13043478260869565\n",
            "Recall: 0.375\n",
            "F1 Score: 0.1935483870967742\n",
            "ROC-AUC: 0.6637323943661972\n",
            "CV ROC-AUC Mean: 0.7288732394366197  | Std: 0.12359606347841197\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Fail (â‰¤15)       0.91      0.72      0.80        71\n",
            "  Pass (>15)       0.13      0.38      0.19         8\n",
            "\n",
            "    accuracy                           0.68        79\n",
            "   macro avg       0.52      0.55      0.50        79\n",
            "weighted avg       0.83      0.68      0.74        79\n",
            "\n",
            "Confusion Matrix:\n",
            " [[51 20]\n",
            " [ 5  3]]\n",
            "\n",
            "Top Positive Predictors (Higher â†’ More Likely to Pass):\n",
            "           Feature  Coefficient  OddsRatio\n",
            "14  Mjob_services     1.353140   3.869558\n",
            "19   Fjob_teacher     1.070378   2.916480\n",
            "0            Medu     0.761710   2.141936\n",
            "25     higher_yes     0.709080   2.032122\n",
            "16    Fjob_health     0.613805   1.847448\n",
            "26   internet_yes     0.473609   1.605779\n",
            "4          famrel     0.437194   1.548356\n",
            "24    nursery_yes     0.379296   1.461255\n",
            "2       studytime     0.303728   1.354900\n",
            "12    Mjob_health     0.272469   1.313203\n",
            "\n",
            "Top Negative Predictors (Higher â†’ More Likely to Fail):\n",
            "            Feature  Coefficient  OddsRatio\n",
            "21      famsup_yes    -0.296713   0.743257\n",
            "1             Fedu    -0.325757   0.721981\n",
            "18   Fjob_services    -0.380604   0.683449\n",
            "9           health    -0.409583   0.663927\n",
            "23  activities_yes    -0.440566   0.643672\n",
            "27    romantic_yes    -0.767033   0.464389\n",
            "17      Fjob_other    -0.929104   0.394907\n",
            "22        paid_yes    -1.063324   0.345306\n",
            "3         failures    -1.767233   0.170805\n",
            "20   schoolsup_yes    -2.613759   0.073259\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load Dataset\n",
        "# -------------------------------\n",
        "data = pd.read_csv(\"student_combined_data_final.csv\")\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Create Binary Target: Pass/Fail\n",
        "# -------------------------------\n",
        "# Fail = 0 (G3 â‰¤ 15), Pass = 1 (G3 > 15)\n",
        "data['G3_math_pass'] = np.where(data['G3_math'] > 15, 1, 0)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Select Relevant Features (No G1, G2)\n",
        "# -------------------------------\n",
        "features = [\n",
        "    'address', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'studytime', 'failures', 'schoolsup',\n",
        "    'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic',\n",
        "    'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences_math'\n",
        "]\n",
        "\n",
        "# Remove rows with missing values in selected columns or target\n",
        "data_clean = data.dropna(subset=features + ['G3_math_pass'])\n",
        "\n",
        "X = data_clean[features]\n",
        "y = data_clean['G3_math_pass']\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Preprocessing (Scaling + Encoding)\n",
        "# -------------------------------\n",
        "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_features),\n",
        "    ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Build Logistic Regression Model\n",
        "# -------------------------------\n",
        "model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('logreg', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Train-Test Split\n",
        "# -------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Train Model\n",
        "# -------------------------------\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Evaluate Performance\n",
        "# -------------------------------\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# Cross-Validation ROC-AUC\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_auc = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n",
        "print(\"CV ROC-AUC Mean:\", cv_auc.mean(), \" | Std:\", cv_auc.std())\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['Fail (â‰¤15)', 'Pass (>15)']))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# -------------------------------\n",
        "# 9. Feature Importance (Coefficients & Odds Ratios)\n",
        "# -------------------------------\n",
        "logreg = model.named_steps['logreg']\n",
        "pre = model.named_steps['preprocess']\n",
        "\n",
        "# Get final feature names after encoding\n",
        "encoded_features = np.concatenate([\n",
        "    numeric_features,\n",
        "    pre.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
        "])\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': encoded_features,\n",
        "    'Coefficient': logreg.coef_[0],\n",
        "    'OddsRatio': np.exp(logreg.coef_[0])\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nTop Positive Predictors (Higher â†’ More Likely to Pass):\\n\", coef_df.head(10))\n",
        "print(\"\\nTop Negative Predictors (Higher â†’ More Likely to Fail):\\n\", coef_df.tail(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTpgO_yCPiP-"
      },
      "source": [
        "## ðŸ“š Part 3: Binary Classification â€” Predicting Pass/Fail in Portuguese (G3_por)\n",
        "\n",
        "We now apply the **same classification process** to Portuguese instead of Mathematics.\n",
        "\n",
        "### âœ… Why Repeat This Model?\n",
        "- The goal is to **compare subjects** and see whether the same factors help predict passing in both Math and Portuguese.\n",
        "- This also helps us answer assignment questions such as:\n",
        "  - Is it possible to predict pass/fail with this dataset?\n",
        "  - Does absenteeism affect performance?\n",
        "  - Does parental education impact success?\n",
        "\n",
        "### âœ… Pipeline (Same as Math Model):\n",
        "âœ” Create binary target (`G3_por_pass`).  \n",
        "âœ” Use same predictors, replacing `absences_math` with `absences_por`.  \n",
        "âœ” Apply same preprocessing (scaling + one-hot encoding).  \n",
        "âœ” Use `LogisticRegression(max_iter=2000, class_weight='balanced')`.  \n",
        "âœ” Evaluate using classification metrics + cross-validation.\n",
        "\n",
        "By keeping the modeling strategy identical, we can **fairly compare** which factors affect Math vs Portuguese differently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL4tb7wiPgS_",
        "outputId": "41ee4822-08b6-43c6-ba8c-3fca7db2bce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Œ G3_por Pass/Fail Model Performance\n",
            "Accuracy: 0.676923076923077\n",
            "Precision: 0.21739130434782608\n",
            "Recall: 0.625\n",
            "F1 Score: 0.3225806451612903\n",
            "ROC-AUC: 0.6869517543859649\n",
            "CV ROC-AUC Mean: 0.696570796460177  | Std: 0.05497964088479665\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Fail (â‰¤15)       0.93      0.68      0.79       114\n",
            "  Pass (>15)       0.22      0.62      0.32        16\n",
            "\n",
            "    accuracy                           0.68       130\n",
            "   macro avg       0.57      0.65      0.56       130\n",
            "weighted avg       0.84      0.68      0.73       130\n",
            "\n",
            "Confusion Matrix:\n",
            " [[78 36]\n",
            " [ 6 10]]\n",
            "\n",
            "Top Positive Predictors (More Likely to Pass Portuguese):\n",
            "            Feature  Coefficient  OddsRatio\n",
            "25      higher_yes     1.651193   5.213197\n",
            "16     Fjob_health     0.856613   2.355170\n",
            "18   Fjob_services     0.786520   2.195741\n",
            "19    Fjob_teacher     0.620713   1.860254\n",
            "0             Medu     0.547811   1.729463\n",
            "17      Fjob_other     0.365254   1.440880\n",
            "26    internet_yes     0.255437   1.291025\n",
            "13      Mjob_other     0.251809   1.286351\n",
            "23  activities_yes     0.251349   1.285759\n",
            "2        studytime     0.250935   1.285227\n",
            "\n",
            "Top Negative Predictors (Higher â†’ More Likely to Fail):\n",
            "           Feature  Coefficient  OddsRatio\n",
            "5        freetime    -0.027558   0.972818\n",
            "1            Fedu    -0.083260   0.920112\n",
            "15   Mjob_teacher    -0.126383   0.881277\n",
            "9          health    -0.209548   0.810951\n",
            "8            Walc    -0.312464   0.731642\n",
            "24    nursery_yes    -0.381907   0.682559\n",
            "10   absences_por    -0.411581   0.662602\n",
            "22       paid_yes    -1.027401   0.357936\n",
            "20  schoolsup_yes    -1.288715   0.275625\n",
            "3        failures    -1.638177   0.194334\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load Dataset\n",
        "# -------------------------------\n",
        "data = pd.read_csv(\"student_combined_data_final.csv\")\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Create Binary Target: Pass/Fail for Portuguese\n",
        "# -------------------------------\n",
        "data['G3_por_pass'] = np.where(data['G3_por'] > 15, 1, 0)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Feature Selection (No G1 or G2 used)\n",
        "# -------------------------------\n",
        "features = [\n",
        "    'address', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'studytime', 'failures', 'schoolsup',\n",
        "    'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic',\n",
        "    'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences_por'\n",
        "]\n",
        "\n",
        "data_clean = data.dropna(subset=features + ['G3_por_pass'])\n",
        "X = data_clean[features]\n",
        "y = data_clean['G3_por_pass']\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Preprocessing (Scaling + Encoding)\n",
        "# -------------------------------\n",
        "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_features),\n",
        "    ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Build Logistic Regression Model\n",
        "# -------------------------------\n",
        "model_por = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('logreg', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Train-Test Split\n",
        "# -------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Train Model\n",
        "# -------------------------------\n",
        "model_por.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Evaluate Model\n",
        "# -------------------------------\n",
        "y_pred = model_por.predict(X_test)\n",
        "y_prob = model_por.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"ðŸ“Œ G3_por Pass/Fail Model Performance\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# Cross-validation ROC-AUC\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_auc = cross_val_score(model_por, X, y, cv=cv, scoring='roc_auc')\n",
        "print(\"CV ROC-AUC Mean:\", cv_auc.mean(), \" | Std:\", cv_auc.std())\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['Fail (â‰¤15)', 'Pass (>15)']))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# -------------------------------\n",
        "# 9. Feature Importance (Coefficients & Odds Ratios)\n",
        "# -------------------------------\n",
        "logreg = model_por.named_steps['logreg']\n",
        "pre = model_por.named_steps['preprocess']\n",
        "\n",
        "encoded_features = np.concatenate([\n",
        "    numeric_features,\n",
        "    pre.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
        "])\n",
        "\n",
        "coef_df_por = pd.DataFrame({\n",
        "    'Feature': encoded_features,\n",
        "    'Coefficient': logreg.coef_[0],\n",
        "    'OddsRatio': np.exp(logreg.coef_[0])\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nTop Positive Predictors (More Likely to Pass Portuguese):\\n\", coef_df_por.head(10))\n",
        "print(\"\\nTop Negative Predictors (Higher â†’ More Likely to Fail):\\n\", coef_df_por.tail(10))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning and merging.\n",
        "\n",
        "1. Replaced column names like G1, G2 and G3 to specific context of G1_math, G2_math, G1_por, G2_por.\n",
        "2. Matched all the data except numeric data that can very by each subject to merge both the data sets."
      ],
      "metadata": {
        "id": "X9a3uBPIIIe1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUGh3FhV3rOm",
        "outputId": "a58da7d2-eadf-4586-8dfe-833ad4b2ebcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched students (identical on all non-subject columns): 162\n",
            "Math-only rows: 233\n",
            "Portuguese-only rows: 485\n",
            "Total rows in merged: 880\n",
            "âœ… Merged dataset saved as 'student_combined_data_final.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Load data ---\n",
        "math = pd.read_csv(\"student_math_data.csv\")\n",
        "por  = pd.read_csv(\"student_por_data.csv\")\n",
        "\n",
        "# --- Grade & subject-specific columns ---\n",
        "math_subject_cols = ['G1_math', 'G2_math', 'G3_math', 'absences_math']\n",
        "por_subject_cols  = ['G1_por', 'G2_por', 'G3_por', 'absences_por']\n",
        "\n",
        "# --- Build strict match key: all shared non-subject, non-grade columns ---\n",
        "common_cols = sorted(list(set(math.columns).intersection(set(por.columns))))\n",
        "exclude_cols = set(math_subject_cols + por_subject_cols)\n",
        "key_cols = [c for c in common_cols if c not in exclude_cols]\n",
        "\n",
        "# --- Keep only key columns + Portuguese subject columns ---\n",
        "por_keep = por[key_cols + por_subject_cols].drop_duplicates(subset=key_cols, keep='first')\n",
        "\n",
        "# --- Merge: all columns from Math + Portuguese subject columns ---\n",
        "merged = pd.merge(\n",
        "    math, por_keep,\n",
        "    on=key_cols,\n",
        "    how='outer'\n",
        ")\n",
        "\n",
        "# --- Diagnostics ---\n",
        "has_math = merged[['G1_math', 'G2_math', 'G3_math']].notna().any(axis=1)\n",
        "has_por  = merged[['G1_por', 'G2_por', 'G3_por']].notna().any(axis=1)\n",
        "matched  = (has_math & has_por).sum()\n",
        "only_math = (has_math & ~has_por).sum()\n",
        "only_por  = (~has_math & has_por).sum()\n",
        "\n",
        "print(f\"Matched students (identical on all non-subject columns): {matched}\")\n",
        "print(f\"Math-only rows: {only_math}\")\n",
        "print(f\"Portuguese-only rows: {only_por}\")\n",
        "print(f\"Total rows in merged: {len(merged)}\")\n",
        "\n",
        "# --- Save final combined dataset ---\n",
        "merged.to_csv(\"student_combined_data_final.csv\", index=False)\n",
        "print(\"âœ… Merged dataset saved as 'student_combined_data_final.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build the first models!\n",
        "\n",
        "Linear model for G3_math"
      ],
      "metadata": {
        "id": "ad4HN4P5IEuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# CLEAN LINEAR MODEL FOR G3_math (with only relevant predictors)\n",
        "# ======================================\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# --- Load dataset ---\n",
        "data = pd.read_csv(\"student_combined_data_final.csv\")\n",
        "\n",
        "# --- Define target ---\n",
        "target = 'G3_math'\n",
        "\n",
        "# --- Columns weâ€™ll use (academically meaningful features only) ---\n",
        "keep_cols = [\n",
        "    'address','Medu','Fedu','Mjob','Fjob','studytime','failures',\n",
        "    'schoolsup','famsup','paid','activities','nursery','higher',\n",
        "    'internet','romantic','famrel','freetime','goout','Dalc','Walc',\n",
        "    'health','absences_math'\n",
        "]\n",
        "\n",
        "# --- Drop rows with missing data in selected columns or target ---\n",
        "subset = data.dropna(subset=[target] + keep_cols).copy()\n",
        "\n",
        "# --- Define X and y ---\n",
        "X = subset[keep_cols]\n",
        "y = subset[target]\n",
        "\n",
        "# --- Identify numeric and categorical columns ---\n",
        "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# --- Preprocessing: standardize numeric, one-hot encode categorical ---\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols)\n",
        "])\n",
        "\n",
        "# --- Linear regression pipeline ---\n",
        "math_model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# --- Train-test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Fit model ---\n",
        "math_model.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluate ---\n",
        "train_r2 = math_model.score(X_train, y_train)\n",
        "test_r2  = math_model.score(X_test, y_test)\n",
        "cv_r2    = cross_val_score(math_model, X, y, cv=5, scoring='r2').mean()\n",
        "\n",
        "print(\"\\nðŸ“˜ Clean Linear Model for G3_math\")\n",
        "print(f\"Training RÂ²: {train_r2:.3f}\")\n",
        "print(f\"Testing  RÂ²: {test_r2:.3f}\")\n",
        "print(f\"5-Fold CV RÂ²: {cv_r2:.3f}\")\n"
      ],
      "metadata": {
        "id": "xkEpx751IEWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d8b8bd6-d411-4850-a262-8b725f7cacc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“˜ Clean Linear Model for G3_math\n",
            "Training RÂ²: 0.283\n",
            "Testing  RÂ²: 0.044\n",
            "5-Fold CV RÂ²: 0.088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Extract coefficients after preprocessing ---\n",
        "pre = math_model.named_steps['preprocess']\n",
        "reg = math_model.named_steps['regressor']\n",
        "\n",
        "# Numeric + categorical names\n",
        "num_cols = pre.transformers_[0][2]\n",
        "cat_encoder = pre.transformers_[1][1]\n",
        "cat_cols = pre.transformers_[1][2]\n",
        "cat_names = cat_encoder.get_feature_names_out(cat_cols)\n",
        "\n",
        "# Combine names and coefficients\n",
        "feature_names = np.concatenate([num_cols, cat_names])\n",
        "coefs = reg.coef_\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefs,\n",
        "    'AbsCoef': np.abs(coefs)\n",
        "}).sort_values(by='AbsCoef', ascending=False)\n",
        "\n",
        "print(\"\\nðŸ“Š Top 15 Features Influencing G3_math:\")\n",
        "print(coef_df.head(15).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgQ5hEBoJDLB",
        "outputId": "b3327b14-a0da-4860-897b-6db95bd570f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Top 15 Features Influencing G3_math:\n",
            "      Feature  Coefficient  AbsCoef\n",
            "   higher_yes     1.864197 1.864197\n",
            " Fjob_teacher     1.778002 1.778002\n",
            "  Mjob_health     1.617405 1.617405\n",
            "     failures    -1.483045 1.483045\n",
            "Mjob_services     1.264003 1.264003\n",
            "schoolsup_yes    -1.176369 1.176369\n",
            "   famsup_yes    -1.174677 1.174677\n",
            "        goout    -0.914959 0.914959\n",
            " romantic_yes    -0.851519 0.851519\n",
            "   Fjob_other    -0.790806 0.790806\n",
            "    address_U     0.649292 0.649292\n",
            "         Walc     0.549227 0.549227\n",
            "    studytime     0.540147 0.540147\n",
            "  Fjob_health     0.539806 0.539806\n",
            " Mjob_teacher    -0.521427 0.521427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear model for G3_por"
      ],
      "metadata": {
        "id": "oeDcB4TPoQ6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# LINEAR MODEL FOR G3_por (same logic as math)\n",
        "# ======================================\n",
        "\n",
        "# --- Define target ---\n",
        "target = 'G3_por'\n",
        "\n",
        "# --- Columns weâ€™ll use ---\n",
        "keep_cols = [\n",
        "    'address','Medu','Fedu','Mjob','Fjob','studytime','failures',\n",
        "    'schoolsup','famsup','paid','activities','nursery','higher',\n",
        "    'internet','romantic','famrel','freetime','goout','Dalc','Walc',\n",
        "    'health','absences_por'\n",
        "]\n",
        "\n",
        "# --- Drop rows with missing data in selected columns or target ---\n",
        "subset = data.dropna(subset=[target] + keep_cols).copy()\n",
        "\n",
        "# --- Define X and y ---\n",
        "X = subset[keep_cols]\n",
        "y = subset[target]\n",
        "\n",
        "# --- Identify numeric and categorical columns ---\n",
        "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# --- Preprocessing: standardize numeric, one-hot encode categorical ---\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols)\n",
        "])\n",
        "\n",
        "# --- Linear regression pipeline ---\n",
        "por_model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# --- Train-test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Fit model ---\n",
        "por_model.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluate ---\n",
        "train_r2 = por_model.score(X_train, y_train)\n",
        "test_r2  = por_model.score(X_test, y_test)\n",
        "cv_r2    = cross_val_score(por_model, X, y, cv=5, scoring='r2').mean()\n",
        "\n",
        "print(\"\\nðŸ“˜ Clean Linear Model for G3_por\")\n",
        "print(f\"Training RÂ²: {train_r2:.3f}\")\n",
        "print(f\"Testing  RÂ²: {test_r2:.3f}\")\n",
        "print(f\"5-Fold CV RÂ²: {cv_r2:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xwNlTiQpKeC",
        "outputId": "689f009e-ea9a-4136-9584-01b22837beca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“˜ Clean Linear Model for G3_por\n",
            "Training RÂ²: 0.329\n",
            "Testing  RÂ²: 0.230\n",
            "5-Fold CV RÂ²: 0.176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Extract coefficients for Portuguese model ---\n",
        "pre = por_model.named_steps['preprocess']\n",
        "reg = por_model.named_steps['regressor']\n",
        "\n",
        "# Numeric + categorical names\n",
        "num_cols = pre.transformers_[0][2]\n",
        "cat_encoder = pre.transformers_[1][1]\n",
        "cat_cols = pre.transformers_[1][2]\n",
        "cat_names = cat_encoder.get_feature_names_out(cat_cols)\n",
        "\n",
        "# Combine names and coefficients\n",
        "feature_names = np.concatenate([num_cols, cat_names])\n",
        "coefs = reg.coef_\n",
        "\n",
        "coef_por = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefs,\n",
        "    'AbsCoef': np.abs(coefs)\n",
        "}).sort_values(by='AbsCoef', ascending=False)\n",
        "\n",
        "print(\"\\nðŸ“Š Top 15 Features Influencing G3_por:\")\n",
        "print(coef_por.head(15).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZyWqODnAq1D",
        "outputId": "8ff92e7e-7a4a-4f9f-c93e-a2e382cb8e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Top 15 Features Influencing G3_por:\n",
            "      Feature  Coefficient  AbsCoef\n",
            "   higher_yes     1.710989 1.710989\n",
            "schoolsup_yes    -1.093523 1.093523\n",
            "     failures    -0.899637 0.899637\n",
            "  Mjob_health     0.691130 0.691130\n",
            "    address_U     0.666919 0.666919\n",
            " internet_yes     0.618528 0.618528\n",
            "     paid_yes    -0.592236 0.592236\n",
            "  Fjob_health     0.589793 0.589793\n",
            " Fjob_teacher     0.553384 0.553384\n",
            "    studytime     0.485899 0.485899\n",
            "Fjob_services    -0.451688 0.451688\n",
            " romantic_yes    -0.408490 0.408490\n",
            "Mjob_services     0.383790 0.383790\n",
            "       health    -0.305687 0.305687\n",
            "  nursery_yes    -0.295233 0.295233\n"
          ]
        }
      ]
    }
  ]
}
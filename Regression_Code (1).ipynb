{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sp3-K7KjuBU"
      },
      "source": [
        "## ðŸ§© Part 1: Merging Math and Portuguese Datasets\n",
        "\n",
        "The original data is provided in two separate files â€” one for **Mathematics (student-math)** and one for **Portuguese (student-por)**.  \n",
        "There is **no unique student ID**, so we merge the datasets using all **non-grade, non-absences** columns that identify a student (such as school, age, sex, address, family background, etc.).\n",
        "\n",
        "We excluded subject-specific fields like:  \n",
        "- `G1_math`, `G2_math`, `G3_math`, `absences_math`  \n",
        "- `G1_por`, `G2_por`, `G3_por`, `absences_por`\n",
        "\n",
        "This ensures that only students with exactly matching personal and demographic data are considered the *same student* in both subjects.\n",
        "\n",
        "If a student exists in only one dataset, they are still kept (via outer join), and missing grades for the other subject are filled as NaN.\n",
        "\n",
        "The final output is saved as: **`student_combined_data_final.csv`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUGh3FhV3rOm",
        "outputId": "a58da7d2-eadf-4586-8dfe-833ad4b2ebcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matched students (identical on all non-subject columns): 162\n",
            "Math-only rows: 233\n",
            "Portuguese-only rows: 485\n",
            "Total rows in merged: 880\n",
            "âœ… Merged dataset saved as 'student_combined_data_final.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Load data ---\n",
        "math = pd.read_csv(\"student-mat.csv\")\n",
        "por  = pd.read_csv(\"student-por.csv\")\n",
        "\n",
        "# --- Grade & subject-specific columns ---\n",
        "math_subject_cols = ['G1_math', 'G2_math', 'G3_math', 'absences_math']\n",
        "por_subject_cols  = ['G1_por', 'G2_por', 'G3_por', 'absences_por']\n",
        "\n",
        "# --- Build strict match key: all shared non-subject, non-grade columns ---\n",
        "common_cols = sorted(list(set(math.columns).intersection(set(por.columns))))\n",
        "exclude_cols = set(math_subject_cols + por_subject_cols)\n",
        "key_cols = [c for c in common_cols if c not in exclude_cols]\n",
        "\n",
        "# --- Keep only key columns + Portuguese subject columns ---\n",
        "por_keep = por[key_cols + por_subject_cols].drop_duplicates(subset=key_cols, keep='first')\n",
        "\n",
        "# --- Merge: all columns from Math + Portuguese subject columns ---\n",
        "merged = pd.merge(\n",
        "    math, por_keep,\n",
        "    on=key_cols,\n",
        "    how='outer'\n",
        ")\n",
        "\n",
        "# --- Diagnostics ---\n",
        "has_math = merged[['G1_math', 'G2_math', 'G3_math']].notna().any(axis=1)\n",
        "has_por  = merged[['G1_por', 'G2_por', 'G3_por']].notna().any(axis=1)\n",
        "matched  = (has_math & has_por).sum()\n",
        "only_math = (has_math & ~has_por).sum()\n",
        "only_por  = (~has_math & has_por).sum()\n",
        "\n",
        "print(f\"Matched students (identical on all non-subject columns): {matched}\")\n",
        "print(f\"Math-only rows: {only_math}\")\n",
        "print(f\"Portuguese-only rows: {only_por}\")\n",
        "print(f\"Total rows in merged: {len(merged)}\")\n",
        "\n",
        "# --- Save final combined dataset ---\n",
        "merged.to_csv(\"student_combined_data_final.csv\", index=False)\n",
        "print(\"âœ… Merged dataset saved as 'student_combined_data_final.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad4HN4P5IEuu"
      },
      "source": [
        "## ðŸ“Š Part 2: Linear Regression Model to Predict Final Math Grade (G3_math)\n",
        "\n",
        "We now build a **linear regression model** to predict the final Math grade (`G3_math`) using only meaningful non-grade predictors.\n",
        "\n",
        "### âœ… Why Linear Regression?\n",
        "- The assignment specifically requires using **linear models**.\n",
        "- Linear models are **interpretable** â€” coefficient values show how each feature affects the grade.\n",
        "- They work well with numeric + one-hot encoded categorical data.\n",
        "\n",
        "### âœ… Important Rules Applied:\n",
        "- We **do not use G1 or G2** (previous grades), because the dataset description warns they are highly correlated with G3.\n",
        "- We only include behavioral, demographic, educational support, and family features.\n",
        "\n",
        "### âœ… Preprocessing Steps:\n",
        "1. Identify numerical and categorical features.\n",
        "2. Use `StandardScaler` to normalize numeric features.\n",
        "3. Use `OneHotEncoder` for categorical features.\n",
        "4. Combine both using a `ColumnTransformer`.\n",
        "5. Fit a `LinearRegression()` model using a pipeline.\n",
        "6. Check model performance using **Train RÂ²**, **Test RÂ²**, and **5-Fold Cross-Validation RÂ²**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkEpx751IEWp",
        "outputId": "6d8b8bd6-d411-4850-a262-8b725f7cacc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“˜ Clean Linear Model for G3_math\n",
            "Training RÂ²: 0.283\n",
            "Testing  RÂ²: 0.044\n",
            "5-Fold CV RÂ²: 0.088\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# CLEAN LINEAR MODEL FOR G3_math (with only relevant predictors)\n",
        "# ======================================\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# --- Load dataset ---\n",
        "data = pd.read_csv(\"student_combined_data_final.csv\")\n",
        "\n",
        "# --- Define target ---\n",
        "target = 'G3_math'\n",
        "\n",
        "# --- Columns weâ€™ll use (academically meaningful features only) ---\n",
        "keep_cols = [\n",
        "    'address','Medu','Fedu','Mjob','Fjob','studytime','failures',\n",
        "    'schoolsup','famsup','paid','activities','nursery','higher',\n",
        "    'internet','romantic','famrel','freetime','goout','Dalc','Walc',\n",
        "    'health','absences_math'\n",
        "]\n",
        "\n",
        "# --- Drop rows with missing data in selected columns or target ---\n",
        "subset = data.dropna(subset=[target] + keep_cols).copy()\n",
        "\n",
        "# --- Define X and y ---\n",
        "X = subset[keep_cols]\n",
        "y = subset[target]\n",
        "\n",
        "# --- Identify numeric and categorical columns ---\n",
        "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# --- Preprocessing: standardize numeric, one-hot encode categorical ---\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols)\n",
        "])\n",
        "\n",
        "# --- Linear regression pipeline ---\n",
        "math_model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# --- Train-test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Fit model ---\n",
        "math_model.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluate ---\n",
        "train_r2 = math_model.score(X_train, y_train)\n",
        "test_r2  = math_model.score(X_test, y_test)\n",
        "cv_r2    = cross_val_score(math_model, X, y, cv=5, scoring='r2').mean()\n",
        "\n",
        "print(\"\\nðŸ“˜ Clean Linear Model for G3_math\")\n",
        "print(f\"Training RÂ²: {train_r2:.3f}\")\n",
        "print(f\"Testing  RÂ²: {test_r2:.3f}\")\n",
        "print(f\"5-Fold CV RÂ²: {cv_r2:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZglzE_RkZo7"
      },
      "source": [
        "## ðŸ“Œ Part 3: Interpreting Feature Importance for Math Performance\n",
        "\n",
        "After training the model, we extract the **regression coefficients** to see which features have the strongest effect on `G3_math`.\n",
        "\n",
        "### âœ… How to Interpret Coefficients:\n",
        "- **Positive coefficient** â†’ Feature increases final grade.\n",
        "- **Negative coefficient** â†’ Feature decreases final grade.\n",
        "- Since numeric features are standardized, coefficient magnitudes are comparable.\n",
        "\n",
        "We sort features by absolute coefficient values to find the **top 15 most influential predictors** of G3 in Math.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgQ5hEBoJDLB",
        "outputId": "b3327b14-a0da-4860-897b-6db95bd570f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Top 15 Features Influencing G3_math:\n",
            "      Feature  Coefficient  AbsCoef\n",
            "   higher_yes     1.864197 1.864197\n",
            " Fjob_teacher     1.778002 1.778002\n",
            "  Mjob_health     1.617405 1.617405\n",
            "     failures    -1.483045 1.483045\n",
            "Mjob_services     1.264003 1.264003\n",
            "schoolsup_yes    -1.176369 1.176369\n",
            "   famsup_yes    -1.174677 1.174677\n",
            "        goout    -0.914959 0.914959\n",
            " romantic_yes    -0.851519 0.851519\n",
            "   Fjob_other    -0.790806 0.790806\n",
            "    address_U     0.649292 0.649292\n",
            "         Walc     0.549227 0.549227\n",
            "    studytime     0.540147 0.540147\n",
            "  Fjob_health     0.539806 0.539806\n",
            " Mjob_teacher    -0.521427 0.521427\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Extract coefficients after preprocessing ---\n",
        "pre = math_model.named_steps['preprocess']\n",
        "reg = math_model.named_steps['regressor']\n",
        "\n",
        "# Numeric + categorical names\n",
        "num_cols = pre.transformers_[0][2]\n",
        "cat_encoder = pre.transformers_[1][1]\n",
        "cat_cols = pre.transformers_[1][2]\n",
        "cat_names = cat_encoder.get_feature_names_out(cat_cols)\n",
        "\n",
        "# Combine names and coefficients\n",
        "feature_names = np.concatenate([num_cols, cat_names])\n",
        "coefs = reg.coef_\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefs,\n",
        "    'AbsCoef': np.abs(coefs)\n",
        "}).sort_values(by='AbsCoef', ascending=False)\n",
        "\n",
        "print(\"\\nðŸ“Š Top 15 Features Influencing G3_math:\")\n",
        "print(coef_df.head(15).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeDcB4TPoQ6L"
      },
      "source": [
        "## ðŸ“š Part 4: Linear Regression Model for Portuguese Grades (G3_por)\n",
        "\n",
        "We repeat exactly the same process as for Math, but now predicting **`G3_por`**.\n",
        "\n",
        "### âœ… Why Repeat the Same Model?\n",
        "- The assignment encourages comparing performance **across both subjects**.\n",
        "- This helps us answer: *Do the same factors influence Math and Portuguese equally?*\n",
        "- Evaluation uses the same metrics: Train RÂ², Test RÂ², and 5-Fold CV RÂ².\n",
        "\n",
        "The only difference is:\n",
        "- We replace `absences_math` with `absences_por`\n",
        "- Target variable becomes `G3_por`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xwNlTiQpKeC",
        "outputId": "689f009e-ea9a-4136-9584-01b22837beca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“˜ Clean Linear Model for G3_por\n",
            "Training RÂ²: 0.329\n",
            "Testing  RÂ²: 0.230\n",
            "5-Fold CV RÂ²: 0.176\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# LINEAR MODEL FOR G3_por (same logic as math)\n",
        "# ======================================\n",
        "\n",
        "# --- Define target ---\n",
        "target = 'G3_por'\n",
        "\n",
        "# --- Columns weâ€™ll use ---\n",
        "keep_cols = [\n",
        "    'address','Medu','Fedu','Mjob','Fjob','studytime','failures',\n",
        "    'schoolsup','famsup','paid','activities','nursery','higher',\n",
        "    'internet','romantic','famrel','freetime','goout','Dalc','Walc',\n",
        "    'health','absences_por'\n",
        "]\n",
        "\n",
        "# --- Drop rows with missing data in selected columns or target ---\n",
        "subset = data.dropna(subset=[target] + keep_cols).copy()\n",
        "\n",
        "# --- Define X and y ---\n",
        "X = subset[keep_cols]\n",
        "y = subset[target]\n",
        "\n",
        "# --- Identify numeric and categorical columns ---\n",
        "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# --- Preprocessing: standardize numeric, one-hot encode categorical ---\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols)\n",
        "])\n",
        "\n",
        "# --- Linear regression pipeline ---\n",
        "por_model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# --- Train-test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Fit model ---\n",
        "por_model.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluate ---\n",
        "train_r2 = por_model.score(X_train, y_train)\n",
        "test_r2  = por_model.score(X_test, y_test)\n",
        "cv_r2    = cross_val_score(por_model, X, y, cv=5, scoring='r2').mean()\n",
        "\n",
        "print(\"\\nðŸ“˜ Clean Linear Model for G3_por\")\n",
        "print(f\"Training RÂ²: {train_r2:.3f}\")\n",
        "print(f\"Testing  RÂ²: {test_r2:.3f}\")\n",
        "print(f\"5-Fold CV RÂ²: {cv_r2:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuNyM2NCkiV9"
      },
      "source": [
        "## ðŸ“Œ Part 5: Feature Importance for G3_por\n",
        "\n",
        "Just like in Math, we extract all feature coefficients from the Portuguese regression model.\n",
        "\n",
        "### âœ… What We Look For:\n",
        "- Which features have the strongest positive or negative impact on Portuguese scores?\n",
        "- Do the same variables (like study time, failures, parental education) affect both subjects?\n",
        "- Are there differences in how social behavior or family structure influences performance in language vs math?\n",
        "\n",
        "The output shows the **top 15 most influential features** for `G3_por`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZyWqODnAq1D",
        "outputId": "8ff92e7e-7a4a-4f9f-c93e-a2e382cb8e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Top 15 Features Influencing G3_por:\n",
            "      Feature  Coefficient  AbsCoef\n",
            "   higher_yes     1.710989 1.710989\n",
            "schoolsup_yes    -1.093523 1.093523\n",
            "     failures    -0.899637 0.899637\n",
            "  Mjob_health     0.691130 0.691130\n",
            "    address_U     0.666919 0.666919\n",
            " internet_yes     0.618528 0.618528\n",
            "     paid_yes    -0.592236 0.592236\n",
            "  Fjob_health     0.589793 0.589793\n",
            " Fjob_teacher     0.553384 0.553384\n",
            "    studytime     0.485899 0.485899\n",
            "Fjob_services    -0.451688 0.451688\n",
            " romantic_yes    -0.408490 0.408490\n",
            "Mjob_services     0.383790 0.383790\n",
            "       health    -0.305687 0.305687\n",
            "  nursery_yes    -0.295233 0.295233\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Extract coefficients for Portuguese model ---\n",
        "pre = por_model.named_steps['preprocess']\n",
        "reg = por_model.named_steps['regressor']\n",
        "\n",
        "# Numeric + categorical names\n",
        "num_cols = pre.transformers_[0][2]\n",
        "cat_encoder = pre.transformers_[1][1]\n",
        "cat_cols = pre.transformers_[1][2]\n",
        "cat_names = cat_encoder.get_feature_names_out(cat_cols)\n",
        "\n",
        "# Combine names and coefficients\n",
        "feature_names = np.concatenate([num_cols, cat_names])\n",
        "coefs = reg.coef_\n",
        "\n",
        "coef_por = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefs,\n",
        "    'AbsCoef': np.abs(coefs)\n",
        "}).sort_values(by='AbsCoef', ascending=False)\n",
        "\n",
        "print(\"\\nðŸ“Š Top 15 Features Influencing G3_por:\")\n",
        "print(coef_por.head(15).to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
